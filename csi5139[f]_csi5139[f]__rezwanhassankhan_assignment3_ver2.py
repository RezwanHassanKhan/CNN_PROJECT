# -*- coding: utf-8 -*-
"""CSI5139[F] CSI5139[F] _RezwanHassanKhan_Assignment3_Ver2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KsaJ55iN2bRAhEsaYYab1lX1VDVYRyFR
"""

import os
from skimage import io
from natsort import natsorted,ns
from skimage.transform import resize
from skimage.color import rgb2gray
from matplotlib import pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score
from skimage.util import crop

import tensorflow as tf
import tensorflow.keras

import keras
from tensorflow.keras import backend as K
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Flatten,Dropout
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Conv2D,MaxPooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.layers import BatchNormalization

from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2
#from tensorflow.keras.applications.mobilenet_v2.preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
import numpy as np
#from glob import glob
import matplotlib.pyplot as plt

path ="Synthetic_Leopard_Circle"
list_files = os.listdir(path)

list_files = natsorted(list_files)

image_list= []
for filename in list_files:
    image_list.append(io.imread(os.path.join(path,filename)))
print(plt.imshow(image_list[0]))

"""### Cropping Images
<font color= blue> Cropping the white part of the images from each side of the image. We have to be careful that we dont crop too much that the object in the image dont get cut when rotating as it will reduce the accuracy of the model.</font>
"""

crop_image=[]
for i in image_list:
   B = crop(i, ((160, 110), (120, 130), (0,0)), copy=False)
   crop_image.append(B)
   #B = crop(i, ((180, 110), (150, 140), (0,0)), copy=False)

print("BEFORE CROPPING")
print(image_list[0].shape)
print("AFTER CROPPING")
print(crop_image[0].shape)
print(len(image_list))
print(len(crop_image))
A = image_list[0]
B = crop_image[0]
print(A.shape, B.shape)
plt.figure(figsize=(20,10))
plt.subplot(121), plt.imshow(A), plt.axis('off')
plt.subplot(122), plt.imshow(B), plt.axis('off')
plt.show()
print(plt.imshow(crop_image[1]))

#print(crop_image[0])

"""### Reshaping to (100,100,6)"""

resized_image_list=[]
for image in crop_image:
    image = resize(image, (100,100,3))
    resized_image_list.append(image)
print(len(resized_image_list))
print(resized_image_list[1].shape)
print(plt.imshow(resized_image_list[57]))

"""### CONVERTING LIST INTO NP ARRAY"""

image_file=np.array(resized_image_list)

print(image_file[0].max())

"""### Important Note :
<font color= red> Please note that , I have considered the degree difference -45 to 45 as -15 to 15 . It will have no effect on the accuracy as this degree difference was only used to label for my classification and is not involved in  mathematical calculation of images. In short,a degree difference of 3 will correspond to degree difference 1. So instead of having degree from 0 to 357 degree we will have degree from 0 to 119.

I have put all the analysis of the curve at the top of each problem's solution so that TA dont have to search for it at the bottom of each solution.</font>

### Creating Angle Array
I made an array that will correspond the different angles of the image from 0 to 119 degree.</font>
"""

image_name=[]
for i in range(0,len(list_files)):
    image_name.append(i)
print(image_name)

#converting to an np array
image_name=np.array(image_name)

image_name.shape

"""### Creating shuffle index
<font color= blue>Before we pre-process our data we have to divide our dataset in train,test and validation set. So we have to shuffle all our images to avoid data imbalance. So I have created a shuffle index so that I can shuffle both my image list and the label/angle difference list. </font>

"""

x=np.random.permutation(len(image_file))

print(x)

"""### Shuffling all image array and image file name list"""

shuffled_image=image_file[x]
shuffled_imageName=image_name[x]

#print(image_file[0])

#print(plt.imshow(shuffled_image[57]))

#print(shuffled_imageName[0])

#for ele in enumerate(shuffled_imageName):
     #print(ele)

#x1=np.concatenate((image_file[0],image_file[1]),axis=2)
#print(x1.shape)

"""### Diving datat into training, validation and test"""

#image file:
Training_set=shuffled_image[0:90]
Validation_Set=shuffled_image[90:100]
Test_Set=shuffled_image[100:120]

#classes:
Training_class=shuffled_imageName[0:90]
Validation_class=shuffled_imageName[90:100]
Test_class=shuffled_imageName[100:120]

print(Training_set.shape)
print(Validation_Set.shape)
print(Test_Set.shape)

print(Training_class.shape)
print(Validation_class.shape)
print(Test_class.shape)

"""## Explanation of Parining of images :
<font color= blue>  I have paired each image  with images that are between +-45 degrees. So an image paired with the top 15 images has a 3 degree difference until it reaches the last degree that is 45. And it paired with 15 down images until the last image with angle difference of -45 degree. Note that it also paired with itself. So we have 31 pairs of each image. So the data set has 120 images. So we will get 31*120 image pairs. We have to deal with images that have an angle greater than the maximum degree but it pairs images because it's in the range. So we have take the modulus value to find the real difference after we add/subtract image angle's with the image angle that we are pairing with.</font>


<font color= blue>I have also created an array of the degree differences of each image's 31 pairs . So we will have 31*120 pairs of angle difference of pairs of each images.So it will be our labels</font>

### Paring Training set
"""

Train_degree=[]
Train_pair_image=[]
for img in Training_class:
    angle1=img
    for i in range(-15,16):
            angle2=(i+img)%120
            Train_pair_image.append(np.concatenate((image_file[angle1],image_file[angle2]),axis=2))
            Train_degree.append(i)

Train_pair_image=np.array(Train_pair_image)
Train_degree=np.array(Train_degree)
print( Train_pair_image.shape)
print(Train_degree.shape)

print(Train_pair_image[0].min())
print(Train_pair_image[0].max())

print(Train_degree)

"""### Adding +15 to make the range from (-15 - 15 ) to (0 -30)

<font color= blue>The angle differnce between each image is 1 in my case. So the range will be from -15 to 15 degree. As it is not possible to with negative integr value to convert it into categorical form , I have normalised the value from -15 to 15 to 0-30 . And then convert it and then did one hot encoding.</font>
"""

for i in range(len(Train_degree)):
  Train_degree[i]=Train_degree[i]+15
print(Train_degree)

"""### Paring Validation_Set"""

Validation_degree=[]
Validation_pair_image=[]
for img in Validation_class:
    print(img)
    angle1=img
    for i in range(-15,16):
            angle2=(i+img)%120
            print(angle1,angle2)
            Validation_pair_image.append(np.concatenate((image_file[angle1],image_file[angle2]),axis=2))
            Validation_degree.append(i)
Validation_degree=np.array(Validation_degree)
Validation_pair_image=np.array(Validation_pair_image)
print(Validation_pair_image.shape)
print(Validation_degree.shape)

print(Validation_pair_image[0].min())
print(Validation_pair_image[0].max())

print(Validation_degree)

"""### Adding +15 to make the range from (-15 - 15 ) to (0 -30)"""

for i in range(len(Validation_degree)):
  Validation_degree[i]=Validation_degree[i]+15
print(Validation_degree)

"""### Paring Test_Set"""

Test_degree=[]
Test_pair_image=[]
for img in Test_class:
    angle1=img
    for i in range(-15,16):
            angle2=(img+i)%120
            Test_pair_image.append(np.concatenate((image_file[angle1],image_file[angle2]),axis=2))
            Test_degree.append(i)
Test_pair_image=np.array(Test_pair_image)
Test_degree=np.array(Test_degree)
print(Test_pair_image.shape)
print(Test_degree.shape)

print(Test_degree)

"""### Adding +15 to make the range from (-15 - 15 ) to (0 -30)"""

for i in range(len(Test_degree)):
  Test_degree[i]=Test_degree[i]+15
print(Test_degree)

# from tensorflow.keras import backend as K
nClasses =31
# one hot encoding to convert integer value into categorical value for using as our label for classification
y_train_k = tensorflow.keras.utils.to_categorical(Train_degree, num_classes=nClasses)
y_validation_k=tensorflow.keras.utils.to_categorical(Validation_degree, num_classes=nClasses)
y_test_k = tensorflow.keras.utils.to_categorical(Test_degree, num_classes=nClasses)

"""## Explnation of my CNN model network:
<font color=blue>
 My models has 3 Convulunational layers, 2 dense layer and last output layer.. I have increased the filter size of each Convulational layer by 32. The filter size of each layer is 3 by 3 pixel. I didn't do striding with my model and did the same padding so that image does not lose its contents from each side of the images.Input shape of my image is 100,100,6. I reduced the size to this because I don't have enough gpu to train my model with high pixel images .Here I used my activation as relu because I wanted to overcome the vanishing gradient problem.This also help to speed up the training.


The added dense layer is also known as a fully connected layer after I flatten my model's output before feeding to last layers. We used this layer so that our Cnn model trained a bit more before sending the output to the last layer.


<font color=blue>
The reason I didnt use dropout in my model is beacuase there is not a very big difference between the accuracy of the model in training and validation set. Though yes, accuracy is better in training set but this cant be considered as a standadr case of overfitting because model give good and neareer to the accuracy like training set. So as there is no overfitting, I didnt find it useful to use dropout. Additionally inclusion of dropuout reduces learning rate when once I tried to include it here in my model.


Last layer is our layer that will predict our output. There are 31 labels, so the layer size is 31. Here we have used softmax as our activation as our ouput range is between between 0 to 1.
<font color=blue>

We have used our loss as categorical_crossentropy because it uses one hot array to calculate the probability instead of using binary loss or sparse_categorical_crossentropy  as it uses caletogy's index instead of the one hot value.</font>

I have set the epoch value to 200 because both the validation and training error was dropping and running it for a bit longer time make the accuracy graph constant which shows that it has reach to the optimal point. Stopping it before few epoch lead to a chance that it may stop before giving the best result.

<font color=blue>
I have selected my learning rate to be 0.0001 instead of a big learning rate so that it does not miss out the global minima and though it will take a bit more time but this value is a good trade off between accuracy and complexity.



"""

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(100,100,6)))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3, 3)))

model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(96, (3, 3), activation='relu', padding='same'))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))


model.add(Flatten())

model.add(Dense(121, activation='relu'))

model.add(Dense(84, activation='relu'))
#model.add(Dropout(0.16))
model.add(Dense(31, activation='softmax'))

model.compile(Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])

from tensorflow.keras.utils import plot_model
plot_model(model, show_shapes=True, show_layer_names=True)

"""### 3

# ******Explanation of learning curves for training and  validation ******

Training accuracy=   99.75 %

Validation accuracy= 95.16%

Test Accuracy =      95.97 %

<font color=blue>For both Training,and validation set, model accuracy increases with the increased number of epochs. This is because models are doing the same thing again and again for more time which helps them to come up with the best answer.

From the graph we can conclude that :
1.Till 25 epoch the curve is very steep which shows the difference of accuracy is changing at a rapid positive rate. But after 25 epochs, the gradient becomes less steeper but it is still positive. Finally it started to become flat at around 200 epoch. And the same happened with error rate.

This model is an optimal model not giving any under and over fitting as the accuracy in validation,test and training are very close to each other.So this model can classify the difference offset of an image correctly in the most of the cases. </font>

### See if it worked
"""

y_train_k=y_train_k.astype(int)
print(y_train_k.astype(int))
print(y_train_k.shape)

y_validation_k=y_validation_k.astype(int)
print(y_validation_k.astype(int))
print(y_validation_k.shape)

y_test_k=y_test_k.astype(int)
print(y_test_k.astype(int))
print(y_test_k.shape)

nEpochs = 200

history = model.fit(Train_pair_image, y_train_k,epochs=nEpochs, verbose=1,
                    validation_data=(Validation_pair_image, y_validation_k))

print("Training Accuracy:")
model.evaluate(Train_pair_image,y_train_k)

print("Validation Accuracy:")
model.evaluate(Validation_pair_image,y_validation_k)

print("Test Accuracy:")
model.evaluate(Test_pair_image,y_test_k)

"""### Learning curves for training and validation"""

# dictionary keys seems to have changed in version 2
k = ''
if 'accuracy' in history.history :
    k = 'accuracy'

if 'acc' in history.history :
    k = 'acc'

if k != '' :
    plt.plot(history.history[k])
    plt.plot(history.history['val_'+k])
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['train', 'validation'], loc='upper left')
    plt.show()

history.history.keys()
'val_' + k
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

"""# 4 Regression Network

<font color=blue>We need to output  float values between -1 to 1 which corroseposnf to -45 to 45 degree;in my case -15 to 15 degree. So I have changed the degree range from -15 to 15 to -1 to 1. First,I again converted by degree from 0 to 30 to -15 to 15 by subtracting by 15 and then I divided it by 15 to get the range between -1 to 1.</font>

My loss here is mean_squared_error as it's a regression problem outputting the error value in the range of 0 to 1.
I didnt use any activation at my output/lastyer as we dont need it as the output will be already between -1 to 1

<font color=blue>The reason I didnt use dropout in my model is beacuase there is not a very big difference between the accuracy of the model in training and validation set. Though yes, accuracy is better in training set but this cant be considered as a standadr case of overfitting because model give good and neareer to the accuracy like training set.</font>

I have selected my learning rate to be 0.0001 instead of a big learning rate so that it does not miss out the global minima and though it will take a bit more time but this value is a good trade off between accuracy and complexity.

# ******Explanation of learning curves for training and  validation ******

Training MSE        =   0.00042012

Validation MSE    =   0.00072420

Test MSE           =   0.00072201

<font color=blue>For both Training,and validation set, model mse decreases with the increased number of epochs but the change was too minimal so it looks that its a flat curve.

From the graph we can conclude that :
Till 7 to 8 epoch the curve is very steep which shows the difference of MSE is changing at a rapid negative rate. But after that epoch, the gradient becomes less steeper but it is still negative but from the graph it may assume that it's flat and constant but it decreases very slowly with each epoch. Finally it started to become flat at around 80 to 100 epoch. And the same happened with loss rate.

This model is an optimal model not giving any under and over fitting as the accuracy in validation,test and training are very close to each other.So this model can classify the difference offset of an image correctly in most of the cases.
 </font>
"""

Reg_Train_degree=(Train_degree-15)/15
print(Reg_Train_degree)

Reg_Validation_degree=(Validation_degree-15)/15
print(Reg_Validation_degree)

Reg_Test_degree=(Test_degree-15)/15
#print(Reg_Test_degree)

y_train_k = Reg_Train_degree
y_validation_k=Reg_Validation_degree
y_test_k = Reg_Test_degree

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(100,100,6)))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(96, (3, 3), activation='relu', padding='same'))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())

model.add(Dense(121, activation='relu'))
#model.add(Dropout(0.16))
model.add(Dense(84, activation='relu'))

model.add(Dense(1))

model.compile(Adam(lr=0.0001),loss='mean_squared_error',metrics=['mse'])

print(model.summary())

nEpochs = 100

history = model.fit(Train_pair_image, y_train_k,epochs=nEpochs, verbose=1,
                    validation_data=(Validation_pair_image, y_validation_k))

print("Training Accuracy:")
model.evaluate(Train_pair_image,y_train_k)

print("Validation Accuracy:")
model.evaluate(Validation_pair_image,y_validation_k)

print("Test Accuracy:")
model.evaluate(Test_pair_image,y_test_k)

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# accuracies
plt.plot(history.history['mse'], label='train mse')
plt.plot(history.history['val_mse'], label='val mse')
plt.title('Model MSE')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()


import tensorflow as tf

from keras.models import load_model

"""# 5: Basic Transfer Learning

# **Explanation of my fine tuning**
I work with grayscale images for this problem. I have used mobilentv2 architecture as my pre-trained model with the last 5 unfrozen layers and additional 1 convolutional and 1 dense layer.</font>

I have selected my learning rate to be 0.0001 instead of a big learning rate so that it does not miss out the global minima and though it will take a bit more time but this value is a good trade off between accuracy and complexity.

# ******Explanation of learning curves for training and  validation ******

Training MSE        =   0.00052

Validation MSE      =   0.0031

Test MSE           =   0.0024

<font color=blue>For both Training and validation set, model mse decreased with the increased number of epochs but the change was too minimal so it looks that its a flat curve. </font>

From the graph we can conclude that :
Till 7 to 8 epoch the curve is very steep which shows the difference of error is changing at a rapid negative rate. But after that epoch, the gradient becomes less steeper but it is still negative but from the graph it may assume that it's flat and constant but it decreases very slowly with each epoch. Finally it started to become flat at around 170 to 200 epoch. And the same happened with loss rate.  </font>

<font color=blue> This model is a case of moderate overfitting as mse error in validation and test is slightly more than the training set which is also visible in the graph.So this model can classify the difference offset of an image correctly more correctly in the training set than the validation and test set. However it is very negligible to consider, so I didn't fine tune.</font>

I tried to add a Dropout layer but no improvement was seen. I even tried to unfreeze the last 5 layers but it didn't improve that much with a cost of high training time. Maybe decreasing the number of neurons may improve the model but my pc runs with very low gpu and it takes a huge time to again cross check with different hyperparameters.
"""

gray_list=[]
for filename in list_files:
    gray_list.append(rgb2gray(io.imread(os.path.join(path,filename))))
print(plt.imshow(gray_list[0]))
print(gray_list[0].shape)

crop_image=[]
for i in gray_list:
    B = crop(i, ((160, 90), (120, 130)))
    crop_image.append(B)



print(gray_list[0].shape)
print(crop_image[0].shape)
print(len(gray_list))
print(len(crop_image))


A = gray_list[0]

# crop_width{sequence, int}: Number of values to remove from the edges of each axis.
# ((before_1, after_1), â€¦ (before_N, after_N)) specifies unique crop widths at the
# start and end of each axis. ((before, after),) specifies a fixed start and end
# crop for every axis. (n,) or n for integer n is a shortcut for before = after = n
# for all axes.
B = crop_image[0]

print(A.shape, B.shape)
# (220, 220, 3) (70, 120, 3)

plt.figure(figsize=(20,10))
plt.subplot(121), plt.imshow(A), plt.axis('off')
plt.subplot(122), plt.imshow(B), plt.axis('off')
plt.show()

print(plt.imshow(crop_image[1]))

#crop_image[1]

resized_image_list=[]
for image in crop_image:
    image = resize(image, (224,224))
    resized_image_list.append(image)
print(len(resized_image_list))
print(resized_image_list[1].shape)
print(plt.imshow(resized_image_list[57]))

"""# We have created an numpy array containing 0s. This is the depth channed we will leave blank and will be the last channel our paired image </font>"""

import numpy as np
lal=np.zeros((224,224,1))
print(lal.shape)

image_file=np.array(resized_image_list)
image_name=[]
for i in range(0,len(list_files)):
    image_name.append(i)
print(image_name)
image_name=np.array(image_name)

x=np.random.permutation(len(image_file))

shuffled_image=image_file[x]
shuffled_imageName=image_name[x]

#image file:
Training_set=shuffled_image[0:90]
Validation_Set=shuffled_image[90:100]
Test_Set=shuffled_image[100:120]

#classes:
Training_class=shuffled_imageName[0:90]
Validation_class=shuffled_imageName[90:100]
Test_class=shuffled_imageName[100:120]

"""# We have pair rgb images and also reshape each imagre from 224,224 to 224,224,1. We then concatnate 2 images and the blank depth channel created earlier to make it 224,224,3 shape."""

Train_degree=[]
Train_pair_image=[]
for img in Training_class:
    angle1=img
    for i in range(-15,16):
            angle2=(i+img)%120
            Train_pair_image.append(np.concatenate((image_file[angle1].reshape(224,224,1),image_file[angle2].reshape(224,224,1),lal),axis=2))
            Train_degree.append(i)

Train_pair_image=np.array(Train_pair_image)
Train_degree=np.array(Train_degree)
print( Train_pair_image.shape)
print(Train_degree.shape)
print(len(Train_degree))

#print(Train_degree.min())

Train_degree=Train_degree.astype(float)
for i in range(0,len(Train_degree)):
  Train_degree[i]=Train_degree[i]/15

#print(Train_degree.max())
#print(Train_degree.min())

#Train_degree[2]

Validation_degree=[]
Validation_pair_image=[]
for img in Validation_class:
    angle1=img
    for i in range(-15,16):
            angle2=(i+img)%120
            Validation_pair_image.append(np.concatenate((image_file[angle1].reshape(224,224,1),image_file[angle2].reshape(224,224,1),lal),axis=2))
            Validation_degree.append(i)
Validation_degree=np.array(Validation_degree)
Validation_pair_image=np.array(Validation_pair_image)
print(Validation_pair_image.shape)
print(Validation_degree.shape)

Validation_pair_image[:,:,:,:3].shape

#print(Validation_degree)

Validation_degree=Validation_degree.astype(float)
for i in range(0,len(Validation_degree)):
  Validation_degree[i]=Validation_degree[i]/15

#print(Validation_degree)

Test_degree=[]
Test_pair_image=[]
for img in Test_class:
    angle1=img
    for i in range(-15,16):
            angle2=(img+i)%120
            Test_pair_image.append(np.concatenate((image_file[angle1].reshape(224,224,1),image_file[angle2].reshape(224,224,1),lal),axis=2))
            Test_degree.append(i)
Test_pair_image=np.array(Test_pair_image)
Test_degree=np.array(Test_degree)
print(Test_pair_image.shape)
print(Test_degree.shape)

#print(Test_degree)

Test_degree=Test_degree.astype(float)
for i in range(0,len(Test_degree)):
  Test_degree[i]=Test_degree[i]/15

#print(Test_degree)

y_train_k = Train_degree
y_validation_k=Validation_degree
y_test_k = Test_degree

#mobilenet created in such a way that it work with input image shape of 224,224,3. So I didnt change that.
#by setting include_top as false, we want our last layer to be removed from this architecture. That means last layer will not be freezed.
#weight will be the already assigned weeights it got from training on imagenet dataset.
base_model = MobileNetV2(input_shape = (224, 224, 3), include_top = False, weights = "imagenet")

base_model.trainable=True
print(len(base_model.layers))

for layer in base_model.layers[:150] :
  layer.trainable = False

# our layers - you can add more if you want

y=Conv2D(32,(3,3),activation='relu')(base_model.output)
y= Flatten()(y)
y=Dense(84, activation='relu')(y)
#y=Dropout(0.25)(y)
# x = Dense(1000, activation='relu')(x)
prediction = Dense(1,activation='tanh')(y)

# create a model object
model = Model(inputs=base_model.input, outputs=prediction)

# view the structure of the model
model.summary()

model.compile(Adam(lr=0.0001),loss='mean_squared_error',metrics=['mse'])

nEpochs = 200
history = model.fit(Train_pair_image, y_train_k,epochs=nEpochs, verbose=1,
                    validation_data=(Validation_pair_image, y_validation_k))

print("Training Accuracy:")
model.evaluate(Train_pair_image,y_train_k)

print("Validation Accuracy:")
model.evaluate(Validation_pair_image,y_validation_k)

print("Test Accuracy:")
model.evaluate(Test_pair_image,y_test_k)

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()


# accuracies
plt.plot(history.history['mse'], label='train mse')
plt.plot(history.history['val_mse'], label='val mse')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.show()


import tensorflow as tf

from keras.models import load_model

"""# 5.1 Non-sequential Model and Fine Tuning

# **Explanation of my fine tuning**
<font color=blue>I work with Rgb images for this problem. So after pairing each image, I have passed 1st image in left input and 2nd image in right input from each pair for my Siamese network. And then by finding the mean square between these two images we find the difference between the score of images and in this way our model tried to predict its output in one shot classification method.</font>

# ******Explanation of learning curves for training and  validation ******

Training MSE        =   0.00056

Validation MSE      =   0.0067

Test MSE           =   0.0055

<font color=blue>For both Training and validation set, model mse decreased with the increased number of epochs but the change was too minimal so it looks that its a flat curve. </font>

From the graph we can conclude that :
Till 7 to 8 epoch the curve is very steep which shows the difference of error is changing at a rapid negative rate. But after that epoch, the gradient becomes less steeper but it is still negative . From the graph we can see that for the training set, it may assume that it's flat and constant but it decreases very slowly with each epoch. Finally it started to become flat at around 170 to 200 epoch. And the same happened with loss rate.  </font>

<font color=blue>How did I fine tune this model to achieve this current improved result  that was very bad before without fine tuning?
1. Unfreeze the last 5 layers for the model to introduce learning from our data set.
2.Added dropout to reduce the overfitting which was more before. I set the dropout to 0.01 as increasing this forced the model to stop learning .
3. Adding tanh activation helped to improve the result.
4. Increase learning rate to 0.00001 from 0.0001. </font>

This model is a case of overfitting as mse error in validation and test is more than the training set which is also visible in the graph.So this model can classify the difference offset of an image correctly more correctly in the training set than the validation and test set. However the error is not that much either for both validation and training, so I didn't fine tune further.
"""

path ="Synthetic_Leopard_Circle"
list_files = os.listdir(path)

list_files = natsorted(list_files)

image_list= []
for filename in list_files:
    image_list.append(io.imread(os.path.join(path,filename)))
print(plt.imshow(image_list[0]))

crop_image=[]
for i in image_list:
   B = crop(i, ((160, 110), (120, 130), (0,0)), copy=False)
   crop_image.append(B)
   #B = crop(i, ((180, 110), (150, 140), (0,0)), copy=False)

print(image_list[0].shape)
print(crop_image[0].shape)
print(len(image_list))
print(len(crop_image))
A = image_list[0]
B = crop_image[0]
print(A.shape, B.shape)
plt.figure(figsize=(20,10))
plt.subplot(121), plt.imshow(A), plt.axis('off')
plt.subplot(122), plt.imshow(B), plt.axis('off')
plt.show()
print(plt.imshow(crop_image[1]))

#print(crop_image[0])

resized_image_list=[]
for image in crop_image:
    image = resize(image, (160,100,3))
    resized_image_list.append(image)
print(len(resized_image_list))
print(resized_image_list[1].shape)
print(plt.imshow(resized_image_list[57]))

image_file=np.array(resized_image_list)
print(image_file[0].max())
image_name=[]
for i in range(0,len(list_files)):
    image_name.append(i)
print(image_name)
image_name=np.array(image_name)
print(image_name.shape)
x=np.random.permutation(len(image_file))
print(x)
shuffled_image=image_file[x]
shuffled_imageName=image_name[x]

#image file:
Training_set=shuffled_image[0:90]
Validation_Set=shuffled_image[90:100]
Test_Set=shuffled_image[100:120]

#classes:
Training_class=shuffled_imageName[0:90]
Validation_class=shuffled_imageName[90:100]
Test_class=shuffled_imageName[100:120]

Train_degree=[]
Train_pair_image=[]
for img in Training_class:
    angle1=img
    for i in range(-15,16):
            angle2=(i+img)%120
            Train_pair_image.append(np.concatenate((image_file[angle1],image_file[angle2]),axis=2))
            Train_degree.append(i)

Train_pair_image=np.array(Train_pair_image)
Train_degree=np.array(Train_degree)
print( Train_pair_image.shape)
print(Train_degree.shape)

Validation_degree=[]
Validation_pair_image=[]
for img in Validation_class:
    #print(img)
    angle1=img
    for i in range(-15,16):
            angle2=(i+img)%120
            #print(angle1,angle2)
            Validation_pair_image.append(np.concatenate((image_file[angle1],image_file[angle2]),axis=2))
            Validation_degree.append(i)
Validation_degree=np.array(Validation_degree)
Validation_pair_image=np.array(Validation_pair_image)
print(Validation_pair_image.shape)
print(Validation_degree.shape)

Test_degree=[]
Test_pair_image=[]
for img in Test_class:
    angle1=img
    for i in range(-15,16):
            angle2=(img+i)%120
            Test_pair_image.append(np.concatenate((image_file[angle1],image_file[angle2]),axis=2))
            Test_degree.append(i)
Test_pair_image=np.array(Test_pair_image)
Test_degree=np.array(Test_degree)
print(Test_pair_image.shape)
print(Test_degree.shape)

print(Train_degree.min())

Train_degree=Train_degree.astype(float)
for i in range(0,len(Train_degree)):
  Train_degree[i]=Train_degree[i]/15

print(Train_degree.max())
print(Train_degree.min())

print(Validation_degree)

Validation_degree=Validation_degree.astype(float)
for i in range(0,len(Validation_degree)):
  Validation_degree[i]=Validation_degree[i]/15
print(Validation_degree)


print(Test_degree)

Test_degree=Test_degree.astype(float)
for i in range(0,len(Test_degree)):
  Test_degree[i]=Test_degree[i]/15

print(Test_degree)

y_train_k =Train_degree
y_validation_k=Validation_degree
y_test_k = Test_degree

base_model= MobileNetV2(input_shape = (160,100, 3), include_top = False, weights = "imagenet")

base_model.trainable=True
print(len(base_model.layers))

for layer in base_model.layers[0:150] :
  layer.trainable = False

#Building a sequential model
input_shape=(160, 100, 3)
left_input = Input(input_shape)
right_input = Input(input_shape)

features_1= base_model(left_input)
features_2= base_model(right_input)

y = keras.layers.Concatenate()([features_1,features_2])
y=Conv2D(32,(3,3),activation='relu')(y)
y=BatchNormalization()(y)
y =Flatten()(y)
y=Dense(121, activation='relu')(y)
y=Dropout(0.16)(y)
prediction = Dense(1,activation='tanh')(y)
siamese_net =Model(inputs=[left_input, right_input], outputs=prediction)


siamese_net.compile(Adam(lr=0.00001),loss='mean_squared_error',metrics=['mse'])

#plot_model(siamese_net, show_shapes=True, show_layer_names=True)

from tensorflow.keras.utils import plot_model
plot_model(siamese_net, show_shapes=True, show_layer_names=True)

"""
## Taking the 1st image from each pair and making a new array. That array  image  will feed in my left_input. Taking the 2nd image of each pair and making a new array. These array images will be fed in my right_input. So I will have 6 new image arrays; two for training ,2 for validation and 2 for testing.
"""

a=Train_pair_image[:,:,:,:3]
b= Train_pair_image[:,:,:,3:]
c= Validation_pair_image[:,:,:,:3]
d=Validation_pair_image[:,:,:,3:]
e= Test_pair_image[:,:,:,:3]
f=Test_pair_image[:,:,:,3:]

print(a.shape)
print(b.shape)
print(c.shape)
print(d.shape)
print(e.shape)
print(f.shape)

nEpochs = 200
history =siamese_net.fit(x=[a,b],y=y_train_k,epochs=nEpochs, verbose=1,
                    validation_data=([c,d], y_validation_k))

print('TRAINING ACCURACY')
siamese_net.evaluate(x=[a,b],y=y_train_k)

print("VALIDATION ACCURACY")
siamese_net.evaluate(x=[c,d],y=y_validation_k)

print("TEST ACCURACY")
siamese_net.evaluate(x=[e,f],y=y_test_k)

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Model LOSS')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# accuracies
plt.plot(history.history['mse'], label='train mse')
plt.plot(history.history['val_mse'], label='val mse')
plt.title('Model MSE')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend()
plt.show()


import tensorflow as tf

from keras.models import load_model

